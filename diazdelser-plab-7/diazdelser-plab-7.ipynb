{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Handout 07\n",
    "#### Sara Díaz del Ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import diazdelser_fastatools as ft\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "plt.style.use('dark_background')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Files\n",
    "small_distances_file = './data/small-distances.txt'\n",
    "diistances_file = './data/distances.txt'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ex. 1 _((5+2 pts)_ Naive string matching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (a) _(5 pts)_ Mapping reads\n",
    "\n",
    "Write a function ```map_reads_naive(reads,sequence)``` that takes a collection (e.g., a\n",
    "list) of (short) strings, the reads, and identifies all occurring positions in sequence.\n",
    "The function should return a dictionary, where the keys are those reads that occur in\n",
    "the sequence and the value of a key is a list of positions (i.e., the indices) where the key\n",
    "occurs.\n",
    "\n",
    "E.g. Let 'abracadabra' be the sequence and ```['a','bra','cada','arba']``` be the list\n",
    "of short reads. The function should return a dictionary:\n",
    "```{'a': [0,3,5,7,10], 'bra': [1,8], 'cada': [4]}```\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def map_reads_naive(reads:list,seq:str) -> dict:\n",
    "\t\"\"\"Takes a collection of (short) strings, the reads, and identifies all occurring positions in sequence\"\"\"\n",
    "\tresults = {}\n",
    "\tfor read in reads:\n",
    "\t\tres = [ match.span()[0] for match in re.finditer(re.compile(read), seq) ]\n",
    "\t\t# Remove empty lists\n",
    "\t\tif res:\n",
    "\t\t\tresults[read] = res\n",
    "\treturn results\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "{'a': [0, 3, 5, 7, 10], 'bra': [1, 8], 'cada': [4]}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test it\n",
    "reads = ['a','bra','cada','arba']\n",
    "seq = 'abracadabra'\n",
    "matches = map_reads_naive(reads, seq)\n",
    "matches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### _(Optional 2 pts)_ English words in the genome\n",
    "The function can now, for instance, be used to solve the `vital' problem of identifying English words\n",
    "in the proteome of organisms. Use the dictionary file words.txt and select all the English words with at\n",
    "least four letters. Find the occurrences of English words of at least four letters in the proteomes of\n",
    "Escherichia coli (file ```ecoli-proteome.faa```) and Drosophila melangoster (files ```chrX.faa```, ```chr2L.faa```,\n",
    "```chr2R.faa```, ```chr3L.faa```, ```chr3R.faa```)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Open words.txt file into list\n",
    "def read_list(file:str) -> list:\n",
    "\t\"\"\"Create a \"dictionary\" list from words in a .txt file\"\"\"\n",
    "\twith open (file, 'r') as f:\n",
    "\t\t# filter by length >= 4\n",
    "\t\treturn [word for word in f.read().split() if (len(word)>=4)]\n",
    "\n",
    "english_words = read_list('words.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Open each fasta as string:\n",
    "files_all = ['ecoli-proteome.faa', 'drosophila/chrX.faa', 'drosophila/chr2L.faa', 'drosophila/chr3L.faa',\n",
    "\t\t 'drosophila/chr2R.faa', 'drosophila/chr3R.faa']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "file = ['ecoli-proteome-test.faa']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def find_english_words(files:list) ->dict:\n",
    "\t\"\"\"Find english words in fasta sequences\"\"\"\n",
    "\tresults = {}\n",
    "\tfor filename in tqdm(files):\n",
    "\t\twith open(filename, 'r') as f:\n",
    "\t\t\tresults[filename] = {}\n",
    "\t\t\tg = ft.single_fasta_sequence(f)\n",
    "\t\t\tfor header,sequence in g:\n",
    "\t\t\t\treads = map_reads_naive(reads=english_words, seq=sequence)\n",
    "\t\t\t\tif reads:\n",
    "\t\t\t\t\tresults[filename][header] = reads\n",
    "\treturn results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [19:33<00:00, 1173.14s/it]\n"
     ]
    }
   ],
   "source": [
    "results1 = find_english_words(file) # Short version: test\n",
    "results = results1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# It takes about 12 hours per file (82 hours predicted) and I don't have that kind of time\n",
    "# results2 = find_english_words(files_all)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# If you run it, save it\n",
    "# with open('results.pickle', 'wb') as f:\n",
    "# \tpickle.dump(results2, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# It it's saved, open it Open it\n",
    "# with open ('results.pickle', 'rb') as f:\n",
    "# \tresults = pickle.load(f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Answer the following questions:\n",
    "\n",
    "\ti. For Escherichia coli and Drosophila melangoster find the longest English words and the proteins in which\n",
    "\t\tthey occur."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In ecoli-proteome-test.faa the longest English word found is 'aasvogels' in >gi|16128175|ref|NP_414724.1| tetraacyldisaccharide-1-P synthase [Escherichia coli str. K-12 substr. MG1655].\n"
     ]
    }
   ],
   "source": [
    "# Sort resulting dictionary by length of key\n",
    "for organism, records, in results.items():\n",
    "\t# Get list of longest word for each record\n",
    "\tlongest_record = { record : max(reads.keys(), key=len) for record, reads in records.items() }\n",
    "\n",
    "\t# Of that list, get overall longest for each organism\n",
    "\tlongest = max(longest_record, key=longest_record.get)\n",
    "\n",
    "\tprint(f\"In {organism} the longest English word found is '{longest_record.get(longest)}' in {longest}.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\tii. Find the proteins of Escherichia coli and Drosophila melangoster containing the most English words of at\n",
    "\t\tleast four letters."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In ecoli-proteome-test.faa:\n",
      "Found 3 English words of at least four letters in >gi|16128175|ref|NP_414724.1| tetraacyldisaccharide-1-P synthase [Escherichia coli str. K-12 substr. MG1655]\n"
     ]
    }
   ],
   "source": [
    "# Check lengths\n",
    "# records={header: reads}\n",
    "for organism, records in results.items():\n",
    "\t# Get list of number of words for each record (if words contain at least 4 letters\n",
    "\tnum_records = { record : len([ x for x in reads.keys() if len(x)>3]) \\\n",
    "\t\t\t\t\t   for record, reads in records.items() }\n",
    "\n",
    "\tmost_records = max(records, key=longest_record.get)\n",
    "\tprint(f'In {organism}:\\nFound {num_records.get(most_records)} English words of at least four letters in {most_records}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ex.2 _(6 pts)_ Speed of matching\n",
    "Finding English words in a proteome is not very close to the practical problem of mapping reads of nucleotide sequences\n",
    "to a genome. A slighlty more realistic scenario is to  use randomly generated data. Note, that for simulating\n",
    "realistic data using simple random sequences is still not very good, as, of course, genomes are not random.\n",
    "For realistic evaluation one would like to either use real experimental data or a more sophisticated randomized\n",
    "model. However, for the assessment of mapping effciency, using simple random data is good enough for now."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (a) _(3 pts)_ Generate random data\n",
    "Write a function ```get_random_data(genome_size,nr_of_reads,read_length,random_seed)```\n",
    "which generates a random string over the alphabet ```{a, c, g, t}``` of length ```genome_size```\n",
    "representing the genome. From this genome, randomly select ```nr_of_reads``` substrings\n",
    "of length ```read_length``` comprising the set of reads. Use the parameter ```random_seed``` to\n",
    "set up the random number generator, so the identical set of random sequences can be\n",
    "reproduced. The function should return a tuple containing the sequence and the set of\n",
    "reads."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def random_reads(sequence:str, read_length:int) -> str:\n",
    "\t\"\"\"Get one random read of given sequence\"\"\"\n",
    "\ti = random.randrange(0, len(sequence) - read_length + 1)\n",
    "\treturn sequence[i : (i+read_length)]\n",
    "\n",
    "def get_random_data(genome_size:int,nr_of_reads:int,read_length:int,random_seed:int=42) ->tuple:\n",
    "\t\"\"\"Generates a random genome\"\"\"\n",
    "\trandom.seed(random_seed)\n",
    "\tsequence = ''.join(random.choices(['a','c','g','t'], k=genome_size))\n",
    "\treads = [ random_reads(sequence,read_length) for i in range(nr_of_reads) ]\n",
    "\treturn sequence, reads"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (b) _(3 pts)_ Test performance of read mapping\n",
    "Use random data to determine the running time of ```map_reads_naive``` of ```Ex.1.(a)``` for:\n",
    "\n",
    "\ti. A genome of size 10^6 and 10^4 reads of length 10.\n",
    "\tii. A genome of size 10^6 and 10^5 reads of length 11.\n",
    "\tiii. A genome of size 10^7 and 10^4 reads of length 12.\n",
    "\n",
    "Compare the running times to those of ```Ex. 3 (b)``` and ```4 (d)```.\n",
    "\n",
    "Warning: ii. and iii. might take quite some time (around 5 min. - 60 min.) so you\n",
    "might want to wait testing on these data sets until you finished everything."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Test it\n",
    "def test_it(genome_size:int,nr_of_reads:int,read_length:int):\n",
    "\t\"\"\"Checks running time of map_read_naive with random data \"\"\"\n",
    "\tsequence, reads = get_random_data(genome_size,nr_of_reads,read_length)\n",
    "\ttic = time.perf_counter()\n",
    "\tmap_reads_naive(reads,sequence)\n",
    "\ttoc = time.perf_counter()\n",
    "\tprint(f\"\\nGenome of size {genome_size} with {nr_of_reads} reads of length {read_length}.\")\n",
    "\tprint(f\"Running time: {toc - tic:0.4f} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Genome of size 1000000 with 10000 reads of length 10.\n",
      "Running time: 75.1108 seconds\n"
     ]
    }
   ],
   "source": [
    "test_it(genome_size=1000000,nr_of_reads=10000,read_length=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Genome of size 1000000 with 100000 reads of length 11.\n",
      "Running time: 475.6360 seconds\n"
     ]
    }
   ],
   "source": [
    "test_it(genome_size=1000000,nr_of_reads=100000,read_length=11)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Genome of size 10000000 with 10000 reads of length 12.\n",
      "Running time: 506.1959 seconds\n"
     ]
    }
   ],
   "source": [
    "test_it(genome_size=10000000,nr_of_reads=10000,read_length=12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ex.3. _(9 pts)_ Preprocessing the \"genome\"\n",
    "One idea for preprocessing is to keep a complete dictionary of all short reads of a fixed length\n",
    "occurring in the genome. For instance, for the \"genome\" ```acgtatcgtatcc``` we would want our\n",
    "dictionary of four-letter word to look like this:\n",
    "```\n",
    "{'acgt': [0],\n",
    "'atcc': [9],\n",
    "'atcg': [4],\n",
    "'cgta': [1, 6],\n",
    "'gtat': [2, 7],\n",
    "'tatc': [3, 8],\n",
    "'tcgt': [5]}\n",
    "```\n",
    "\n",
    "We can generate such a dictionary by scanning the genome sequence once, from left to right,\n",
    "looking at the four letter sequences ```acgt, cgta, gtat,```... and adding the positions to the\n",
    "appropriate dictionary entry. Now, if we want to look for a read (e.g., ```gtatcc```) we look up\n",
    "the positions of the prefix of length 4 (e.g., ```gtat```) and we only need to check if the read\n",
    "occurs at one of the positions indicated by the occurrences of the prefix (e.g., 2 and 7, where\n",
    "the subsequence starting at 7 matches the read)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (a) _(6 pts)_ Implement the read mapping function ```map_reads_lookup(reads,sequence,lookup_size)``` using the outlined strategy.\n",
    "Here, ```lookup_size``` is the size of the substrings to be used in the lookup table.\n",
    "To make this function effcient it should preprocess the sequence once at the beginning\n",
    "of the function and then use the generated lookup dictionary for finding all the reads.\n",
    "It should return a dictionary as described in ex. 1 (a)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def reads_dictonary(seq:str, n:int) -> dict:\n",
    "\t\"\"\"Generates an n-sized-reads dictionary from the given sequence\"\"\"\n",
    "\t# Init dict list\n",
    "\treads_dict = defaultdict(list)\n",
    "\t# Preprocess\n",
    "\tfor i in range(len(seq)-n+1):\n",
    "\t\treads_dict[seq[i:i+n]].append(i)\n",
    "\treturn reads_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def lookup(lookup_dct, read, lookup_size, sequence):\n",
    "\t\"\"\"Check where the read starts with the lookup dictionary.\n",
    "\t  Check the rest with the sequence\"\"\"\n",
    "\tpos = lookup_dct.get(read[0:lookup_size])\n",
    "\tseqmatches = { sequence[p:p+len(read)] : p  for p in pos if pos }\n",
    "\treturn [ pos for match, pos in seqmatches.items() if match == read ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def map_reads_lookup(reads:list, sequence:str, lookup_size:int) -> dict:\n",
    "\t\"\"\"Finds all the reads in a sequence. Preprocesses the sequence once at the beginning\n",
    "\t and then uses the generated lookup dictionary to find all the reads.\"\"\"\n",
    "\n",
    "\t# Pre-process the seq one to create lookup dict\n",
    "\tlookup_dct = reads_dictonary(sequence, lookup_size)\n",
    "\n",
    "\t# Use lookup dict to find all the reads\n",
    "\tresults = { read: lookup(lookup_dct, read, lookup_size, sequence) for read in reads if len(read)>=lookup_size }\n",
    "\n",
    "\treturn results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (b) _(3 pts)_ Use a lookup size of 4 and 8 and determine the running times for the sample data generated in ex. 2 (b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# Test it\n",
    "def test_it2(genome_size:int,nr_of_reads:int,read_length:int, lookup_size:int):\n",
    "\t\"\"\"Checks running time of map_read_naive with random data \"\"\"\n",
    "\t# Generate random data\n",
    "\tsequence, reads = get_random_data(genome_size,nr_of_reads,read_length)\n",
    "\ttic = time.perf_counter()\n",
    "\tmap_reads_lookup(reads,sequence, lookup_size)\n",
    "\ttoc = time.perf_counter()\n",
    "\tprint(f\"\\nGenome of size {genome_size} with {nr_of_reads} reads of length {read_length}.\")\n",
    "\tprint(f\"Running time: {toc - tic:0.4f} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Genome of size 1000000 with 10000 reads of length 10.\n",
      "Running time: 24.2435 seconds\n",
      "\n",
      "Genome of size 1000000 with 10000 reads of length 10.\n",
      "Running time: 0.9436 seconds\n"
     ]
    }
   ],
   "source": [
    "test_it2(genome_size=1000000,nr_of_reads=10000,read_length=10, lookup_size=4)\n",
    "test_it2(genome_size=1000000,nr_of_reads=10000,read_length=10, lookup_size=8)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Genome of size 1000000 with 100000 reads of length 11.\n",
      "Running time: 254.1104 seconds\n",
      "\n",
      "Genome of size 1000000 with 100000 reads of length 11.\n",
      "Running time: 2.4117 seconds\n"
     ]
    }
   ],
   "source": [
    "test_it2(genome_size=1000000,nr_of_reads=100000,read_length=11,lookup_size=4)\n",
    "test_it2(genome_size=1000000,nr_of_reads=100000,read_length=11,lookup_size=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Genome of size 10000000 with 10000 reads of length 12.\n",
      "Running time: 339.5088 seconds\n",
      "\n",
      "Genome of size 10000000 with 10000 reads of length 12.\n",
      "Running time: 12.4669 seconds\n"
     ]
    }
   ],
   "source": [
    "test_it2(genome_size=10000000,nr_of_reads=10000,read_length=12,lookup_size=4)\n",
    "test_it2(genome_size=10000000,nr_of_reads=10000,read_length=12,lookup_size=8)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ex.4 _(10 + 2 pts)_ Preprocessing the reads"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (a) _(4 pts)_ Write a Python class KeywordTree for representing such a keyword tree.\n",
    "The class will need to contain at least one method ```add_word```for adding new words to a tree.\n",
    "\n",
    "A function for generating a keyword tree from a list of reads might then look like this:\n",
    "```\n",
    "def make_keyword_tree(reads):\n",
    "\ttree = KeywordTree()\n",
    "\tfor word in reads:\n",
    "\ttree.add_word(word)\n",
    "\treturn tree\n",
    "```\n",
    "(If you feel like it, consider adding an (optional) argument to the constructor so that\n",
    "the call ```KeywordTree(reads)``` returns a keyword tree where all words in reads have\n",
    "already been added.)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class KeywordTree():\n",
    "\t\"\"\"Represents a keyword tree\"\"\"\n",
    "\tdef __init__(self, reads:list=None):\n",
    "\t\tself.root = {}\n",
    "\t\tself.reads = reads\n",
    "\n",
    "\t\tif self.reads:\n",
    "\t\t\tself.__add_reads()\n",
    "\n",
    "\tdef __add_letter(self,parent,i,word):\n",
    "\t\t\"\"\"Add a letter to node\"\"\"\n",
    "\t\tletter = word[i]\n",
    "\t\tif parent == '*':\n",
    "\t\t\treturn\n",
    "\t\tif i < len(word)-1:\n",
    "\t\t\t# If the letter is not added\n",
    "\t\t\tif not parent.get(letter):\n",
    "\t\t\t\tparent[letter] = {}\n",
    "\t\t\tself.__add_letter(parent=parent[letter],i=i+1, word=word)\n",
    "\t\telse:\n",
    "\t\t\tparent[letter] = '*'\n",
    "\t\t\treturn\n",
    "\n",
    "\tdef add_word(self,word):\n",
    "\t\t\"\"\"Add a word to the keyword tree\"\"\"\n",
    "\t\tself.__add_letter(self.root,0,word)\n",
    "\n",
    "\tdef __add_reads(self):\n",
    "\t\t\"\"\"Add all given reads to the tree\"\"\"\n",
    "\t\tfor word in self.reads:\n",
    "\t\t\tself.add_word(word)\n",
    "\t\treturn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def make_keyword_tree(reads):\n",
    "\ttree = KeywordTree()\n",
    "\tfor word in reads:\n",
    "\t\ttree.add_word(word)\n",
    "\treturn tree.root"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "{'a': '*', 'b': {'r': {'a': '*'}}, 'c': {'a': {'d': {'a': '*'}}}}"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reads = ['a','bra','cada','arba']\n",
    "make_keyword_tree(reads)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "{'a': '*', 'b': {'r': {'a': '*'}}, 'c': {'a': {'d': {'a': '*'}}}}"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reads = ['a','bra','cada','arba']\n",
    "tree = KeywordTree(reads)\n",
    "tree.root"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (b) _(3 pts)_ Write a read mapping function ```map_reads_tree(reads_tree,sequence)```\n",
    "\n",
    "With such a keyword tree, it is easy to check whether a sequence starting at index ```i``` contains a word from the\n",
    "keyword tree: Check if there is an edge from the root of the tree corresponding to the first letter ```sequence[i]```,\n",
    "if so, proceed to ```i+1``` and to the corresponding child; repeat. If a child is marked as a word, the subsequence\n",
    "```sequence[i:i+k+1]``` is a valid word. If at one point, no appropriate edge exist, stop.\n",
    "\n",
    "The process is repeated for all i in the range 0 until len(sequence).\n",
    "\n",
    "Write a read mapping function ```map_reads_tree(reads_tree,sequence)```, which uses\n",
    "keyword trees for read mapping. Here, te argument reads_tree should be the keyword\n",
    "tree generated from the reads. The function, again, should return a dictionary as\n",
    "described in ex. 1 (a)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def is_edge(parent:dict,i:int, k:int, results:dict, seq:str) -> dict:\n",
    "\t\"\"\"Check if theres an edge from parent to child\"\"\"\n",
    "\tif i < len(seq):\n",
    "\t\tif not parent.get(seq[i]):\n",
    "\t\t\treturn results\n",
    "\n",
    "\t\tif parent.get(seq[i]) == '*':\n",
    "\t\t\tresults[seq[k:i+1]].append(k)\n",
    "\t\t\treturn results\n",
    "\n",
    "\t\tparent.get(seq[i])\n",
    "\t\tresults = is_edge(parent.get(seq[i]),i+1, k, results, seq)\n",
    "\n",
    "\treturn results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def map_reads_tree(tree:object,seq:str) -> dict:\n",
    "\t\"\"\"Maps a read_tree\"\"\"\n",
    "\t# This allows us to append positions too each read more easily\n",
    "\tresults = defaultdict(list)\n",
    "\tfor i in range(len(seq)):\n",
    "\t\tresults = is_edge(tree.root,i,i,results, seq)\n",
    "\t# Turn it back into a normal dict\n",
    "\treturn dict(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "{'a': [0, 3, 5, 7, 10], 'bra': [1, 8], 'cada': [4]}"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reads = ['a','bra','cada','arba']\n",
    "tree = KeywordTree(reads)\n",
    "seq = 'abracadabra'\n",
    "map_reads_tree(tree, seq)\n",
    "\n",
    "# Should be : {'a': [0,3,5,7,10], 'bra': [1,8], 'cada': [4]} (CORRECT!)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "####  (c) (Optional 2 pts)\n",
    "Repeat the exercise 1 (b) of finding the longest English words in the proteomes of Escherichia coli and Drosophila\n",
    "melangoster and compare the running times.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Open each fasta as string:\n",
    "files_all = ['ecoli-proteome.faa', 'drosophila/chrX.faa', 'drosophila/chr2L.faa', 'drosophila/chr3L.faa',\n",
    "\t\t 'drosophila/chr2R.faa', 'drosophila/chr3R.faa']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "file = ['ecoli-proteome-test.faa']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def find_english_words(files:list) ->dict:\n",
    "\t\"\"\"Find english words in fasta sequences\"\"\"\n",
    "\tresults = {}\n",
    "\tfor filename in tqdm(files):\n",
    "\t\twith open(filename, 'r') as f:\n",
    "\t\t\tresults[filename] = {}\n",
    "\t\t\tg = ft.single_fasta_sequence(f)\n",
    "\t\t\tfor header,sequence in g:\n",
    "\t\t\t\ttree = KeywordTree(english_words)\n",
    "\t\t\t\treads = map_reads_tree(tree=tree, seq=sequence)\n",
    "\t\t\t\tif reads:\n",
    "\t\t\t\t\tresults[filename][header] = reads\n",
    "\treturn results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:08<00:00, 128.23s/it]\n"
     ]
    }
   ],
   "source": [
    "results3 = find_english_words(file) # Short version: test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [7:58:41<00:00, 4786.94s/it]  \n"
     ]
    }
   ],
   "source": [
    "results4 = find_english_words(files_all) # Long version"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In ecoli-proteome-test.faa the longest English word found is 'aasvogel' in >gi|16128175|ref|NP_414724.1| tetraacyldisaccharide-1-P synthase [Escherichia coli str. K-12 substr. MG1655].\n"
     ]
    }
   ],
   "source": [
    "results = results3\n",
    "# Sort resulting dictionary by length of key\n",
    "for organism, records, in results.items():\n",
    "\t# Get list of longest word for each record\n",
    "\tlongest_record = { record : max(reads.keys(), key=len) for record, reads in records.items() }\n",
    "\t# Of that list, get overall longest for each organism\n",
    "\tlongest = max(longest_record, key=longest_record.get)\n",
    "\tprint(f\"In {organism} the longest English word found is '{longest_record.get(longest)}' in {longest}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In ecoli-proteome-test.faa:\n",
      "Found 2 English words of at least four letters in >gi|16128175|ref|NP_414724.1| tetraacyldisaccharide-1-P synthase [Escherichia coli str. K-12 substr. MG1655]\n"
     ]
    }
   ],
   "source": [
    "# Check lengths\n",
    "# records={header: reads}\n",
    "for organism, records in results.items():\n",
    "\t# Get list of number of words for each record (if words contain at least 4 letters\n",
    "\tnum_records = { record : len([ x for x in reads.keys() if len(x)>3]) \\\n",
    "\t\t\t\t\t   for record, reads in records.items() }\n",
    "\n",
    "\tmost_records = max(records, key=longest_record.get)\n",
    "\tprint(f'In {organism}:\\nFound {num_records.get(most_records)} English words of at least four letters in {most_records}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (d) (3 pts) Determine the running times for the sample data generated in ex. 2 (b)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# Test it\n",
    "def test_it3(genome_size:int,nr_of_reads:int,read_length:int):\n",
    "\t\"\"\"Checks running time of map_read_naive with random data \"\"\"\n",
    "\t# Generate random data\n",
    "\tsequence, reads = get_random_data(genome_size,nr_of_reads,read_length)\n",
    "\n",
    "\ttic = time.perf_counter()\n",
    "\t# Make Keyword tree\n",
    "\ttree = KeywordTree(reads)\n",
    "\t# Lookup\n",
    "\tmap_reads_tree(tree,sequence)\n",
    "\ttoc = time.perf_counter()\n",
    "\n",
    "\tprint(f\"\\nGenome of size {genome_size} with {nr_of_reads} reads of length {read_length}.\")\n",
    "\tprint(f\"Running time: {toc - tic:0.4f} seconds\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Genome of size 1000000 with 10000 reads of length 10.\n",
      "Running time: 5.7910 seconds\n"
     ]
    }
   ],
   "source": [
    "test_it3(genome_size=1000000,nr_of_reads=10000,read_length=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Genome of size 1000000 with 100000 reads of length 11.\n",
      "Running time: 9.0760 seconds\n"
     ]
    }
   ],
   "source": [
    "test_it3(genome_size=1000000,nr_of_reads=100000,read_length=11)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Genome of size 10000000 with 10000 reads of length 12.\n",
      "Running time: 54.6013 seconds\n"
     ]
    }
   ],
   "source": [
    "test_it3(genome_size=10000000,nr_of_reads=10000,read_length=12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}